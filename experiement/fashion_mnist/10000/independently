100 1 1.0109991 0.73046875 0.68145
200 2 0.7878401 0.7734375 0.79305
300 3 0.61790985 0.9140625 0.83765
400 5 0.46037385 0.92578125 0.85825
500 6 0.39641884 0.91015625 0.86714995
600 7 0.31662923 0.98046875 0.8718
700 8 0.3191781 0.9609375 0.8835
800 10 0.25841588 0.98046875 0.8938
900 11 0.22471835 0.98046875 0.8892
1000 12 0.20573926 0.9921875 0.898
1100 14 0.16757698 1.0 0.89489996
1200 15 0.16021007 1.0 0.90435
1300 16 0.15669408 0.9921875 0.89935005
1400 17 0.14086413 0.99609375 0.9029
1500 19 0.12205194 1.0 0.90305
1600 20 0.12436765 1.0 0.9042
1700 21 0.107704885 1.0 0.90534997
1800 23 0.10824021 1.0 0.905
1900 24 0.1057866 1.0 0.9044
2000 25 0.10409963 1.0 0.90779996
2100 26 0.09589899 1.0 0.90615
2200 28 0.083829686 1.0 0.90629995
2300 29 0.092952125 1.0 0.90405
2400 30 0.08225698 1.0 0.90795
2500 31 0.07240644 1.0 0.90845
2600 33 0.07637292 1.0 0.90465
2700 34 0.07339577 1.0 0.90540004
2800 35 0.069504276 1.0 0.90795
2900 37 0.0742833 1.0 0.9067
3000 38 0.073961355 1.0 0.90675
3100 39 0.064779684 1.0 0.90674996
3200 40 0.06305725 1.0 0.90715003
3300 42 0.07496855 1.0 0.90865
3400 43 0.06249948 1.0 0.9082
3500 44 0.05842942 1.0 0.90875
3600 46 0.05621752 1.0 0.90970004
3700 47 0.0612107 1.0 0.90875
3800 48 0.052000493 1.0 0.9077
3900 49 0.056298047 1.0 0.90900004
4000 51 0.052971106 1.0 0.90964997
4100 52 0.055437066 1.0 0.90945005
4200 53 0.0510435 1.0 0.90995
4300 55 0.0558154 1.0 0.90785
4400 56 0.058784075 1.0 0.90895
4500 57 0.046868004 1.0 0.90825
4600 58 0.04897917 1.0 0.9072
4700 60 0.045800734 1.0 0.90925
4800 61 0.043983974 1.0 0.90905
4900 62 0.057372462 1.0 0.911
5000 63 0.04949047 1.0 0.90985
5100 65 0.044777244 1.0 0.9095
5200 66 0.040761285 1.0 0.90995
5300 67 0.043741055 1.0 0.90945
5400 69 0.037536353 1.0 0.91139996
5500 70 0.04291343 1.0 0.9108
5600 71 0.039845373 1.0 0.90935004
5700 72 0.04039176 1.0 0.9078
5800 74 0.039518956 1.0 0.9106
5900 75 0.03524238 1.0 0.9097
6000 76 0.03521357 1.0 0.91135
6100 78 0.0367486 1.0 0.91040003
6200 79 0.038360424 1.0 0.90964997
6300 80 0.034584507 1.0 0.9109
2018-08-07 08:37:53.572839: W tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.37GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
2018-08-07 08:37:53.572897: W tensorflow/stream_executor/cuda/cuda_dnn.cc:2223] 
6400 81 0.035282254 1.0 0.9102
6500 83 0.036753744 1.0 0.90964997
6600 84 0.035472672 1.0 0.9087
6700 85 0.034708112 1.0 0.90955
6800 87 0.03572032 1.0 0.90935004
6900 88 0.036664996 1.0 0.91069996
7000 89 0.03190165 1.0 0.9108
7100 90 0.033444352 1.0 0.90945
7200 92 0.03146655 1.0 0.90935004
7300 93 0.035959125 1.0 0.9102
7400 94 0.030964633 1.0 0.91015
7500 95 0.030644467 1.0 0.9108
7600 97 0.030705087 1.0 0.9103
7700 98 0.030346684 1.0 0.9098
7800 99 0.028829027 1.0 0.90995
7900 101 0.03335253 1.0 0.90915
8000 102 0.03225588 1.0 0.91075003
8100 103 0.028185355 1.0 0.9103
8200 104 0.029574897 1.0 0.91055
8300 106 0.032996815 1.0 0.91125
8400 107 0.032626957 1.0 0.91085005
8500 108 0.028659254 1.0 0.91115
8600 110 0.028898295 1.0 0.9106
8700 111 0.030786537 1.0 0.9118
8800 112 0.029711146 1.0 0.91085
8900 113 0.029203724 1.0 0.9112
9000 115 0.028322503 1.0 0.91135
9100 116 0.028747711 1.0 0.9107
9200 117 0.02913123 1.0 0.9108
9300 119 0.03089457 1.0 0.91075003
9400 120 0.027359039 1.0 0.91085
9500 121 0.025629718 1.0 0.91165
9600 122 0.032408807 1.0 0.9117
9700 124 0.026039224 1.0 0.91094995
9800 125 0.030751048 1.0 0.912
9900 126 0.031818155 1.0 0.91040003
10000 127 0.028664012 1.0 0.9106
10100 129 0.03335299 1.0 0.91055
10200 130 0.029390875 1.0 0.91174996
10300 131 0.029542284 1.0 0.91174996
10400 133 0.026178606 1.0 0.91115
10500 134 0.029361708 1.0 0.91215
10600 135 0.026872018 1.0 0.91115
10700 136 0.027203105 1.0 0.91120005
10800 138 0.027542565 1.0 0.91205
10900 139 0.026617007 1.0 0.9117
11000 140 0.02920952 1.0 0.91185
11100 142 0.03132937 1.0 0.91129994
11200 143 0.025529386 1.0 0.9117
11300 144 0.026207894 1.0 0.9122
11400 145 0.024771651 1.0 0.91225
11500 147 0.027407466 1.0 0.91209996
11600 148 0.026459347 1.0 0.91165
11700 149 0.02789871 1.0 0.91205
11800 151 0.024306174 1.0 0.91190004
11900 152 0.026583377 1.0 0.912
12000 153 0.030890537 1.0 0.9117
12100 154 0.02413572 1.0 0.91205
12200 156 0.026401334 1.0 0.91190004
12300 157 0.024437513 1.0 0.9115
12400 158 0.025645327 1.0 0.91165
12500 159 0.024594814 1.0 0.9118
12600 161 0.024855834 1.0 0.91174996
12700 162 0.026302066 1.0 0.91260004
12800 163 0.023659699 1.0 0.91165
12900 165 0.029950073 1.0 0.91174996
13000 166 0.028825765 1.0 0.9119
13100 167 0.02365286 1.0 0.91235
13200 168 0.027807185 1.0 0.91225004
13300 170 0.026297163 1.0 0.91235
13400 171 0.025076702 1.0 0.91225004
13500 172 0.026579756 1.0 0.9119
13600 174 0.025496814 1.0 0.912
13700 175 0.02866463 1.0 0.91174996
13800 176 0.025698017 1.0 0.9117
13900 177 0.027047986 1.0 0.91205
14000 179 0.023860797 1.0 0.91205
14100 180 0.02507465 1.0 0.9119

