100 0 1.0191619 0.64453125 0.6366
200 1 0.8659559 0.6953125 0.76339996
300 1 0.7476522 0.77734375 0.78625
400 2 0.6231589 0.875 0.81535
500 3 0.57466674 0.85546875 0.85564995
600 3 0.5743761 0.91796875 0.87785
700 4 0.42497963 0.94921875 0.87874997
800 5 0.3573267 0.89453125 0.8718
900 5 0.30395883 0.96484375 0.89475
1000 6 0.31503522 0.93359375 0.8772
1100 7 0.2264739 0.9609375 0.89715004
1200 7 0.2913387 0.99609375 0.90779996
1300 8 0.24659438 0.97265625 0.9073
1400 8 0.19533916 0.99609375 0.9073
1500 9 0.18576387 0.98046875 0.90355
1600 10 0.16254884 0.9921875 0.90795004
1700 10 0.15132156 0.9921875 0.90540004
1800 11 0.14703324 0.98828125 0.90970004
1900 12 0.123920985 0.9921875 0.90709996
2000 12 0.12542431 0.9921875 0.9125
2100 13 0.112037666 0.984375 0.89605
2200 14 0.10167199 0.99609375 0.89885
2300 14 0.10574913 0.98828125 0.91110003
2400 15 0.09406517 1.0 0.91485
2500 15 0.10672847 0.99609375 0.9091
2600 16 0.100535735 1.0 0.90795004
2700 17 0.08459716 1.0 0.91205
2800 17 0.081750505 0.99609375 0.9076
2900 18 0.091126226 1.0 0.91475
3000 19 0.07887861 1.0 0.9094
3100 19 0.0807147 1.0 0.91244996
3200 20 0.07602045 1.0 0.91465
3300 21 0.08524657 0.99609375 0.9137
3400 21 0.06995596 1.0 0.91525
3500 22 0.068421096 1.0 0.91625
3600 23 0.06510016 1.0 0.91845
3700 23 0.072358325 1.0 0.91705
3800 24 0.06338434 1.0 0.90845
3900 24 0.0656538 1.0 0.91480005
4000 25 0.059128635 0.99609375 0.91595
4100 26 0.06570234 1.0 0.9189
4200 26 0.05862306 1.0 0.91830003
4300 27 0.05894547 1.0 0.9191
4400 28 0.055945218 1.0 0.9188
4500 28 0.07161797 1.0 0.91104996
4600 29 0.05832833 1.0 0.92050004
4700 30 0.053847954 1.0 0.911
4800 30 0.058830198 1.0 0.91495
4900 31 0.05740535 1.0 0.91550004
5000 31 0.050916366 1.0 0.9201
5100 32 0.058356673 1.0 0.9181
5200 33 0.053163074 1.0 0.9197
5300 33 0.05225773 1.0 0.92035
5400 34 0.05133416 1.0 0.91785
5500 35 0.04896068 1.0 0.9176
5600 35 0.052787468 1.0 0.9202
5700 36 0.050306097 1.0 0.92184997
5800 37 0.04516449 1.0 0.92235005
5900 37 0.045108505 1.0 0.92045
6000 38 0.047903955 1.0 0.9208
6100 39 0.04451126 1.0 0.92085
6200 39 0.05381201 1.0 0.92135
6300 40 0.045924626 1.0 0.9207
6400 40 0.044726454 1.0 0.9228
6500 41 0.03956288 1.0 0.92190003
6600 42 0.041055806 1.0 0.92105
6700 42 0.040341504 1.0 0.92114997
6800 43 0.04281639 1.0 0.92184997
6900 44 0.044761367 1.0 0.9223
7000 44 0.041074052 1.0 0.92209995
7100 45 0.045988515 1.0 0.92175
7200 46 0.042396873 1.0 0.9203
7300 46 0.042540602 1.0 0.92205
7400 47 0.039457887 1.0 0.9211
7500 47 0.041703474 1.0 0.91865003
2018-08-07 06:39:16.952950: W tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.37GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
2018-08-07 06:39:16.953050: W tensorflow/stream_executor/cuda/cuda_dnn.cc:2223] 
7600 48 0.043156587 1.0 0.92225003
7700 49 0.04106143 1.0 0.9235
7800 49 0.039604742 1.0 0.92289996
7900 50 0.038055256 1.0 0.92114997
8000 51 0.036414266 1.0 0.92285
8100 51 0.03850733 1.0 0.9218
8200 52 0.036444716 1.0 0.9211
8300 53 0.039463025 1.0 0.92275
2018-08-07 06:39:38.368754: W tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.37GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
2018-08-07 06:39:38.368861: W tensorflow/stream_executor/cuda/cuda_dnn.cc:2223] 
8400 53 0.037654467 1.0 0.9232
8500 54 0.04282368 1.0 0.9228
8600 55 0.03971237 1.0 0.92200005
8700 55 0.035876952 1.0 0.92265
2018-08-07 06:39:48.517950: W tensorflow/stream_executor/cuda/cuda_dnn.cc:2223] 
8800 56 0.040532492 1.0 0.92260003
8900 56 0.033504035 1.0 0.9238
9000 57 0.04026691 1.0 0.92205
9100 58 0.035704777 1.0 0.92345
9200 58 0.037324414 1.0 0.92275
9300 59 0.03525299 1.0 0.923
9400 60 0.03465358 1.0 0.9233
9500 60 0.037643056 1.0 0.92345
9600 61 0.032423656 1.0 0.92415
9700 62 0.034416363 1.0 0.92355
9800 62 0.03686336 1.0 0.9241
9900 63 0.03691765 1.0 0.9239
10000 63 0.039853595 1.0 0.9242
10100 64 0.033665597 1.0 0.9232
10200 65 0.038745843 1.0 0.9231
10300 65 0.03279706 1.0 0.9231
10400 66 0.036034495 1.0 0.9233
10500 67 0.033030037 1.0 0.92355
10600 67 0.034540456 1.0 0.9235
10700 68 0.031352565 1.0 0.92425
10800 69 0.031853568 1.0 0.92420006
10900 69 0.031720623 1.0 0.92365
11000 70 0.03344418 1.0 0.924
11100 71 0.033256687 1.0 0.92345
11200 71 0.03435708 1.0 0.92410004
11300 72 0.03562165 1.0 0.92359996
11400 72 0.03307087 1.0 0.92359996
11500 73 0.031764217 1.0 0.92305
11600 74 0.040613383 1.0 0.92385
11700 74 0.032127097 1.0 0.92375004
11800 75 0.032602396 1.0 0.9236
11900 76 0.033478603 1.0 0.9238
12000 76 0.03216416 1.0 0.92365
12100 77 0.034124162 1.0 0.9234
12200 78 0.031069726 1.0 0.9238
12300 78 0.032105416 1.0 0.9242
12400 79 0.0327955 1.0 0.92405
12500 79 0.029835887 1.0 0.92385

