100 0 0.98265654 0.61328125 0.61285
200 1 0.8786105 0.765625 0.78005
300 1 0.6707347 0.8515625 0.8155
400 2 0.6107231 0.8828125 0.83935
500 3 0.5192847 0.8203125 0.84385
600 3 0.5572986 0.91015625 0.87285
700 4 0.4299585 0.9296875 0.89145005
800 5 0.35921586 0.94921875 0.8776
900 5 0.34602463 0.9453125 0.90185
1000 6 0.27887467 0.96484375 0.9024
1100 7 0.22916055 0.97265625 0.9086
1200 7 0.270934 0.97265625 0.90534997
1300 8 0.18863723 0.953125 0.8949
1400 8 0.20893025 0.98046875 0.9029
1500 9 0.17891072 0.95703125 0.8922
1600 10 0.15061563 0.98828125 0.91324997
1700 10 0.14662857 0.97265625 0.8919
1800 11 0.12737773 0.97265625 0.89320004
1900 12 0.118143894 0.98828125 0.89540005
2000 12 0.12429161 0.99609375 0.906
2100 13 0.121430136 0.9921875 0.90174997
2200 14 0.11023472 0.9921875 0.89655
2300 14 0.102806464 0.9921875 0.89805
2400 15 0.09039729 0.98828125 0.89555
2500 15 0.09427959 1.0 0.9108
2600 16 0.09761951 0.99609375 0.90495
2700 17 0.08607905 1.0 0.90855
2800 17 0.089288436 0.99609375 0.89985
2900 18 0.08091009 1.0 0.90475
3000 19 0.088433444 1.0 0.90265
3100 19 0.07733792 0.99609375 0.89435
3200 20 0.08783032 1.0 0.91475
3300 21 0.07832276 1.0 0.91445
3400 21 0.06627999 1.0 0.914
3500 22 0.07676452 1.0 0.91400003
3600 23 0.07231746 1.0 0.9125
3700 23 0.07040882 1.0 0.9135
3800 24 0.07006953 1.0 0.9131
3900 24 0.06230622 1.0 0.9094
4000 25 0.060656868 1.0 0.91859996
4100 26 0.06365081 1.0 0.921
4200 26 0.06149521 1.0 0.9211
4300 27 0.077222764 1.0 0.9203
4400 28 0.053354338 1.0 0.9223
4500 28 0.05638451 1.0 0.92015004
4600 29 0.05709344 1.0 0.91645
4700 30 0.06342164 1.0 0.91795003
4800 30 0.05299279 1.0 0.92155004
4900 31 0.061938487 1.0 0.91665
5000 31 0.057536878 1.0 0.91260004
5100 32 0.05055202 1.0 0.92055
5200 33 0.051078655 1.0 0.92245
5300 33 0.049247377 1.0 0.9221
5400 34 0.052783664 1.0 0.92445004
5500 35 0.046567082 1.0 0.92069995
5600 35 0.05373136 1.0 0.9194
5700 36 0.05072672 1.0 0.9235
5800 37 0.046651743 1.0 0.92175
5900 37 0.04956525 1.0 0.92235005
6000 38 0.04530321 1.0 0.92509997
6100 39 0.04622039 1.0 0.925
6200 39 0.046018377 1.0 0.92245
6300 40 0.041628137 1.0 0.92355
6400 40 0.04174994 1.0 0.92410004
6500 41 0.040419996 1.0 0.9234
6600 42 0.040399615 1.0 0.9245
6700 42 0.04380945 1.0 0.9237
6800 43 0.039510943 1.0 0.9249
6900 44 0.04207988 1.0 0.92375004
7000 44 0.046468932 1.0 0.9237
7100 45 0.041803673 1.0 0.9246
7200 46 0.041078497 1.0 0.92475
7300 46 0.03683667 1.0 0.92604995
7400 47 0.03575926 1.0 0.92455
7500 47 0.038582474 1.0 0.92545
7600 48 0.03659539 1.0 0.92575
7700 49 0.03836916 1.0 0.92585003
7800 49 0.03939268 1.0 0.92569995
7900 50 0.037850823 1.0 0.92569995
8000 51 0.03696715 1.0 0.92359996
8100 51 0.033905953 1.0 0.92625
8200 52 0.033636555 1.0 0.92555
8300 53 0.040545292 1.0 0.9261
8400 53 0.033771414 1.0 0.9266
8500 54 0.034859292 1.0 0.92575
8600 55 0.03841939 1.0 0.9257
8700 55 0.03717421 1.0 0.92675
8800 56 0.033208996 1.0 0.9256
8900 56 0.035967816 1.0 0.92585003
2018-08-07 05:37:42.468097: W tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.37GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
2018-08-07 05:37:42.468213: W tensorflow/stream_executor/cuda/cuda_dnn.cc:2223] 
9000 57 0.033283696 1.0 0.92675
9100 58 0.036561146 1.0 0.92675
9200 58 0.03529709 1.0 0.92575
9300 59 0.032633767 1.0 0.92745
9400 60 0.03279788 1.0 0.92705
9500 60 0.03431025 1.0 0.92555
9600 61 0.033621304 1.0 0.92719996
9700 62 0.034708038 1.0 0.9268
9800 62 0.033354666 1.0 0.92785
9900 63 0.031819273 1.0 0.92725
10000 63 0.034409504 1.0 0.92775
10100 64 0.033071123 1.0 0.9271
10200 65 0.030989151 1.0 0.92725
10300 65 0.033716492 1.0 0.9271
10400 66 0.03465896 1.0 0.92719996
10500 67 0.033149585 1.0 0.92735
10600 67 0.030698318 1.0 0.92789996
10700 68 0.033882856 1.0 0.92765
10800 69 0.02975956 1.0 0.92719996
10900 69 0.03716105 1.0 0.92770004
11000 70 0.0324964 1.0 0.928
11100 71 0.031147774 1.0 0.9275
11200 71 0.033982977 1.0 0.92795
11300 72 0.03198792 1.0 0.92805004
11400 72 0.034509182 1.0 0.92824996
11500 73 0.033713996 1.0 0.9278
11600 74 0.030156065 1.0 0.9281
11700 74 0.029155698 1.0 0.9279
11800 75 0.032495685 1.0 0.9282
11900 76 0.03299185 1.0 0.9286
12000 76 0.031671803 1.0 0.92815
12100 77 0.033770863 1.0 0.92805004
12200 78 0.02981994 1.0 0.92865
12300 78 0.031370223 1.0 0.9282
12400 79 0.034408033 1.0 0.9284
12500 79 0.033733435 1.0 0.92815

